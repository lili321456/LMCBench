import numpy as np

from sklearn.metrics import roc_auc_score

def pearson_correlation(x, y):
    """
    Calculate the Pearson correlation coefficient between the two variables.

    Input:
    x (list or numpy array): The data for the first variable
    y (list or numpy array): The data for the second variable

    Output:
    float: Pearson correlation coefficient, ranging between [-1, 1]
    """
    # Converts the input to a numpy array
    x = np.array(x)
    y = np.array(y)
    
    # mean
    mean_x = np.mean(x)
    mean_y = np.mean(y)
    
    # covariance
    covariance = np.sum((x - mean_x) * (y - mean_y))
    
    # standard deviation
    std_x = np.sqrt(np.sum((x - mean_x) ** 2))
    std_y = np.sqrt(np.sum((y - mean_y) ** 2))
    
    # Pearson correlation coefficient
    if std_x == 0 or std_y == 0:
        return 0  # If the standard deviation is 0, return 0
    else:
        return covariance / (std_x * std_y)

# machine: Input machine accuracy in order of main table
# artificial: Enter the artificial accuracy in the order of the main table (calculate the median of the artificial accuracy for the threshold parameter of the AUC function)
machine=[0.3811,0.4222,0.4473,0.461,0.2995,0.3137,0.4462,0.4093,0.4579,0.5609,0.2209,0.2989,0.5303,0.3294,0.5213,0.5483]
artificial=[0.52,0.54,0.59,0.67,0.25,0.30,0.57,0.54,0.69,0.73,0.57,0.48,0.71,0.38,0.72,0.74]
# Calculate the Pearson correlation coefficient
correlation = pearson_correlation(machine, artificial)

# Output result
print("Pearson correlation coefficient:", correlation)

def dcg(scores):
    return np.sum([
        (rel / np.log2(idx + 2)) for idx, rel in enumerate(scores)
    ])

def ndcg(machine_scores, artificial_scores):
    # Sort the corresponding artificial_scores by machine_scores
    sorted_indices = np.argsort(machine_scores)[::-1]  # Descending arrangement
    ranked_artificial = np.array(artificial_scores)[sorted_indices]

    # Calculate DCG and IDCG
    dcg_score = dcg(ranked_artificial)
    idcg_score = dcg(sorted(artificial_scores, reverse=True))

    # Avoid division by zero errors
    if idcg_score == 0:
        return 0.0

    return dcg_score / idcg_score


# Calculating NDCG
ndcg_score = ndcg(machine, artificial)

print(f"NDCG Score: {ndcg_score:.4f}")


def calculate_auc(machine_scores, artificial_scores, threshold=0.57):
    """
    The AUC values of model prediction accuracy and manual labeling accuracy were calculated.

    para：
    - machine_scores: Accuracy list of model predictions (floating point)
    - artificial_scores: Manually annotated accuracy list (floating point numbers)
    - threshold: Binary threshold (default: 0.5)

    return：
    - value of AUC 
    """
    # The manual labeling accuracy is converted to two-class labels
    binary_labels = [1 if score >= threshold else 0 for score in artificial_scores]
    auc_value = roc_auc_score(binary_labels, machine_scores)
    
    return auc_value

# Calculating AUC
auc_result = calculate_auc(machine, artificial)
print("AUC:", auc_result)
